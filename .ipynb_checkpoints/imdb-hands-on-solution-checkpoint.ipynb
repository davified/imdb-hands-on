{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_train = pd.read_csv('./data/raw/labeledTrainData.tsv', sep='\\t')\n",
    "print data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8196_8</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont know why people think this is such a ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7166_2</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie could have been very good, but come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10633_1</td>\n",
       "      <td>0</td>\n",
       "      <td>I watched this video at a friend's house. I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>319_1</td>\n",
       "      <td>0</td>\n",
       "      <td>A friend of mine bought this film for £1, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8713_10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;This movie is full of references. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sentiment                                             review\n",
       "0   5814_8          1  With all this stuff going down at the moment w...\n",
       "1   2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2   7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3   3630_4          0  It must be assumed that those who praised this...\n",
       "4   9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
       "5   8196_8          1  I dont know why people think this is such a ba...\n",
       "6   7166_2          0  This movie could have been very good, but come...\n",
       "7  10633_1          0  I watched this video at a friend's house. I'm ...\n",
       "8    319_1          0  A friend of mine bought this film for £1, and ...\n",
       "9  8713_10          1  <br /><br />This movie is full of references. ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helpers\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for idx in range(data_train.review.shape[0]):\n",
    "    text = BeautifulSoup(data_train.review[idx], 'lxml')\n",
    "    texts.append(clean_str(text.get_text().encode('ascii','ignore')))\n",
    "    labels.append(data_train.sentiment[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "('Label:', 1)\n",
      "('Text: ', 'with all this stuff going down at the moment with mj ive started listening to his music, watching the odd documentary here and there, watched the wiz and watched moonwalker again. maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. some of it has subtle messages about mjs feeling towards the press and also the obvious message of drugs are bad mkay.visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring. some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him.the actual feature film bit when it finally starts is only on for 20 minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord. why he wants mj dead so bad is beyond me. because mj overheard his plans? nah, joe pescis character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates mjs music.lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence. also, the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.bottom line, this movie is for people who like mj on one level or another (which i think is most people). if not, then stay away. it does try and give off a wholesome message and ironically mjs bestest buddy in this movie is a girl! michael jackson is truly one of the most talented people ever to grace this planet but is he guilty? well, with all the attention ive gave this subject....hmmm well i dont know because people can be different behind closed doors, i know this for a fact. he is either an extremely nice but stupid guy or one of the most sickest liars. i hope he is not the latter.')\n",
      "-------------\n",
      "('Label:', 1)\n",
      "('Text: ', 'the classic war of the worlds by timothy hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate h. g. wells classic book. mr. hines succeeds in doing so. i, and those who watched his film with me, appreciated the fact that it was not the standard, predictable hollywood fare that comes out every year, e.g. the spielberg version with tom cruise that had only the slightest resemblance to the book. obviously, everyone looks for different things in a movie. those who envision themselves as amateur critics look only to criticize everything they can. others rate a movie on more important bases,like being entertained, which is why most people never agree with the critics. we enjoyed the effort mr. hines put into being faithful to h.g. wells classic novel, and we found it to be very entertaining. this made it easy to overlook what the critics perceive to be its shortcomings.')\n",
      "-------------\n",
      "('Label:', 0)\n",
      "('Text: ', 'the film starts with a manager (nicholas bell) giving welcome investors (robert carradine) to primal park . a secret project mutating a primal animal using fossilized dna, like jurassik park, and some scientists resurrect one of natures most fearsome predators, the sabretooth tiger or smilodon . scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . in addition , a security agent (stacy haiduk) and her mate (brian wimmer) fight hardly against the carnivorous smilodons. the sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. the giant animals savagely are stalking its prey and the group run afoul and fight against one natures most fearsome predators. furthermore a third sabretooth more dangerous and slow stalks its victims.the movie delivers the goods with lots of blood and gore as beheading, hair-raising chills,full of scares when the sabretooths appear with mediocre special effects.the story provides exciting and stirring entertainment but it results to be quite boring .the giant animals are majority made by computer generator and seem totally lousy .middling performances though the players reacting appropriately to becoming food.actors give vigorously physical performances dodging the beasts ,running,bound and leaps or dangling over walls . and it packs a ridiculous final deadly scene. no for small kids by realistic,gory and violent attack scenes . other films about sabretooths or smilodon are the following : sabretooth(2002)by james r hickox with vanessa angel, david keith and john rhys davies and the much better 10.000 bc(2006) by roland emmerich with with steven strait, cliff curtis and camilla belle. this motion picture filled with bloody moments is badly directed by george miller and with no originality because takes too many elements from previous films. miller is an australian director usually working for television (tidal wave, journey to the center of the earth, and many others) and occasionally for cinema ( the man from snowy river, zeus and roxanne,robinson crusoe ). rating : below average, bottom of barrel.')\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('-------------')\n",
    "    print('Label:', labels[i])\n",
    "    print('Text: ', texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize words in movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "# EMBEDDING_DIM = 50\n",
    "# VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80562 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 29, 10, 536, 165, 177, 30, 1, 559, 15, 10067, 198, 643, 2620, 5, 23, 223, 144, 1, 1022, 656, 128, 2, 46, 291, 1, 19356, 2, 291, 11563, 169, 275, 9, 40, 180, 5, 75, 3, 806, 2621, 80, 10, 226, 34, 9, 193, 12, 62, 636, 7, 1, 4263, 40, 5, 275, 93, 52, 57, 325, 723, 26, 6, 2514, 39, 1346, 11563, 6, 168, 5053, 168, 778, 18, 59, 9, 373, 165, 5, 63, 30, 1, 432, 50, 8, 12, 1820, 622, 45, 4, 8, 44, 1296, 3464, 41, 544, 943, 1, 3527, 2, 78, 1, 577, 744, 4, 1653, 22, 73, 2012, 1154, 17, 4, 259, 10, 6, 29, 41, 485, 1874, 35, 894, 21, 2593, 37, 10067, 7, 553, 90, 21, 22, 165, 5, 780, 10, 2, 164, 8, 355, 45, 199, 678, 10067, 32, 14, 5, 1, 227, 4, 10, 16, 17, 10067, 2, 87, 4, 23, 444, 58, 130, 11, 26, 89, 8, 14, 1, 444, 59, 43, 277, 6, 62, 323, 4, 86, 1, 776, 778, 18, 222, 50, 8, 412, 513, 6, 61, 19, 14, 886, 229, 39, 35, 16070, 1, 3507, 1670, 715, 2, 904, 11301, 6, 1076, 13, 3, 11900, 29, 974, 1392, 1624, 133, 26, 487, 10067, 341, 35, 73, 6, 720, 68, 84, 10067, 23, 2454, 13854, 904, 104, 11, 26, 469, 79, 5, 119, 8, 6, 26, 34, 6, 19357, 1653, 521, 35, 9, 11564, 275, 26, 40, 4153, 223, 761, 4, 636, 178, 7, 10, 37, 10067, 1585, 80, 3, 515, 2, 3, 2362, 2, 1, 221, 2078, 2720, 715, 78, 1, 162, 210, 24, 66, 1, 5054, 4, 3, 5351, 50, 8, 380, 5, 1418, 1, 73, 715, 13, 630, 668, 780, 775, 15, 27, 550, 384, 583, 3, 221, 758, 4, 94, 3465, 3, 1313, 830, 131, 1331, 344, 10, 16, 6, 14, 79, 34, 37, 10067, 19, 27, 644, 39, 155, 59, 9, 101, 6, 87, 79, 43, 20, 90, 783, 240, 8, 122, 350, 2, 197, 120, 3, 7680, 744, 2, 3620, 2050, 7, 10, 16, 6, 3, 242, 485, 1874, 6, 366, 27, 4, 1, 87, 1017, 79, 121, 5, 1683, 10, 1201, 17, 6, 26, 2514, 69, 15, 29, 1, 688, 198, 519, 10, 871, 7168, 69, 9, 88, 119, 84, 79, 67, 25, 271, 493, 4579, 3549, 9, 119, 10, 14, 3, 188, 26, 6, 342, 32, 574, 323, 17, 374, 226, 39, 27, 4, 1, 87, 19358, 19359, 9, 439, 26, 6, 20, 1, 1559]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0])\n",
    "# Note: this is just a vectorized form of the first movie review in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data before feeding into neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding:\n",
      "('Length of sequences list:', 25000)\n",
      "('Shape of labels list:', 25000)\n",
      "After padding:\n",
      "('Shape of data tensor:', (25000, 1000))\n",
      "('Shape of label tensor:', (25000, 2))\n"
     ]
    }
   ],
   "source": [
    "# Zeropad sequences, because Keras expects vectors of a fixed shape\n",
    "print('Before padding:')\n",
    "print('Length of sequences list:', len(sequences))\n",
    "print('Shape of labels list:', len(labels))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "\n",
    "print('After padding:')\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and tes sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews in traing and validation set \n",
      "[ 9345.  9405.]\n",
      "[ 3155.  3095.]\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive and negative reviews in traing and validation set ')\n",
    "print y_train.sum(axis=0)\n",
    "print y_val.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 100000 word vectors in Glove 6B 100d.\n"
     ]
    }
   ],
   "source": [
    "# embeddings_index = {}\n",
    "# GLOVE_DIR = \"./data/RNN\"\n",
    "# f = open(os.path.join(GLOVE_DIR, 'glove.first-100k.6B.50d.txt'))\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=20000, output_dim=32, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 693,402\n",
      "Trainable params: 693,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/3\n",
      "18750/18750 [==============================] - 704s - loss: 0.6493 - acc: 0.6718 - val_loss: 0.5223 - val_acc: 0.7671\n",
      "Epoch 2/3\n",
      "18750/18750 [==============================] - 690s - loss: 0.3858 - acc: 0.8435 - val_loss: 0.3446 - val_acc: 0.8557\n",
      "Epoch 3/3\n",
      "18750/18750 [==============================] - 688s - loss: 0.2390 - acc: 0.9084 - val_loss: 0.3040 - val_acc: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a25855a90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 epoches\n",
    "\n",
    "training accuracy   : 09163\n",
    "\n",
    "validation accuracy : 0.8523  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
